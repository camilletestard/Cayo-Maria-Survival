#Load library
library(ggplot2)
################################
#Set parameters specific to the:
#1. Study population
#2. Behavior studied
#2. Observation method
n_simulations = 100 #Number of simulations
#Study population
group_size = 20 #group size
p_behavior_visibility = 0.7 # observability of behavior (common or cryptic)
p_terrain_visibility = 0.9 # visibility of individuals due to terrain (forest vs. open field)
p_visibility= p_behavior_visibility * p_terrain_visibility  # Final visibility, which is a combination of the sources of occlusions.
#Behavior studied
mean=60; sd=15
n_events = round(abs(rnorm(group_size, mean, sd))); #frequency of behavior
#number of behavioral events in the day per individual, or rarity of behavior
#Assuming each individual engages in the behavior at normally distributed frequencies)
#We could sample from another distribution (e.g. more skewed)
behavior_duration = 2 #behavior duration in sec
#Observation method
#NOTES:
# Not have a unique time per behavior? draw from a distribution around a mean?
# Visibility at individual, behavior and habitat level
#total observation time
n_hours = 7 #number of hours of observation in the day
time_in_s = n_hours*60*60 #number of seconds of observations in a day
#continuous focal
focal_duration_hrs = 1/12 #time of focal in hours (i.e. 10min)
focal_duration_s = focal_duration_hrs*3600 #focal duration in seconds
focal_break_time_min = 5 # minimum break time between focals in min
focal_break_time_s = focal_break_time_min*60 # minimum break time between focals in sec
n_focals = 20 # number of focals in a day
total_focal_h = n_focals*focal_duration_hrs #focal observation time in hours
total_focal_s = n_focals*focal_duration_s #focal observation time in seconds
#group scans
scan_obsTime_perID=1; #scan time needed per individual. Assuming 1sec
scan_duration = scan_obsTime_perID*group_size #duration of a scan observations in sec, scales with group size
scan_break_time_s = 60 # minimum break time between scans in seconds
num_scans = total_focal_s/scan_duration #equivalent # scans than the focal hours observed
#initiate outcomes of simulation
focaltime_perID = matrix(NA,n_simulations,group_size) #seconds of focal observation per ID
focalsamples_perID = matrix(NA,n_simulations,group_size)  #number of focal observations per ID
behav_timeObserved_focal_perID = matrix(NA,n_simulations,group_size)  #seconds of behavior observed per ID
behav_boutsObserved_focal_perID = matrix(NA,n_simulations,group_size)  # number of bouts observed per ID
focal_rate_perID = matrix(NA,n_simulations,group_size)  #observed rate of behavior per ID
behav_timeObserved_focal_total = matrix(NA,1,n_simulations) #seconds of behavior observed for all IDs
behav_boutsObserved_focal_total = matrix(NA,1,n_simulations) #number of bouts observed for all IDs
scansamples_perID = matrix(NA,n_simulations,group_size) # number of scan samples per ID
behav_boutsObserved_scan_perID = matrix(NA,n_simulations,group_size) # number of bouts observed per ID
scan_rate_perID = matrix(NA,n_simulations,group_size) #observed rate of behavior per ID
behav_timeObserved_scan_total = matrix(NA,1,n_simulations) #seconds of behavior observed for all IDs
behav_boutsObserved_scan_total = matrix(NA,1,n_simulations) #number of bouts observed for all IDs
true_rate_behav_perID = matrix(NA,n_simulations,group_size)
sim=1
#Initialize matrices
# size: [number IDs X Time in sec]
behavior = matrix(0, group_size, time_in_s) #Real behaviors
focals = matrix(0, group_size, time_in_s) #Focal observation time points
scans = matrix(0, group_size, time_in_s) #Group scans time points
#######################
#Create behavior matrix
#randomly assign mid-point of behavior during the day for each individual
id=1; e=1; event_id=1
for (id in 1:group_size){ #For each individual
event_times = sample(seq(behavior_duration, time_in_s-behavior_duration,
by = behavior_duration), n_events[id] )#sample behavioral events times (mid-point of behavior)
#Sample behavioral event times during the day with a minimum
#time lapse between behavioral events ('by' time).
#Currently min time lapse = length of the behavior
#Fill in the 'real' behavior matrix
for (e in 1:length(event_times)){ #for all behavior events
behavior[id,(event_times[e]-behavior_duration/2+1):(event_times[e]+behavior_duration/2)]=event_id
#Set each behavior bout in the day with a unique identifier event_id
event_id=event_id+1
}
}
########################################################
#Find observed behaviors using continuous focal sampling
#Assign focal times during the day
#Set focal list for the day
if (group_size<n_focals){ #if there are less individuals than #focals in a day
focal_id_list=sample(1:group_size, n_focals, replace = T)
}else{ #If there are more or equal #individuals in a day
focal_id_list=sample(1:group_size, n_focals)}
#Set focal mid-points
focal_times = sample(seq(focal_duration_s,time_in_s-focal_duration_s,
by=focal_break_time_s), n_focals)
#Sample focal mid time points during the day with a minimum
#time lapse between behavioral events ('by' time).
#Currently time lapse = focal_break_time
#Fill in the 'focal' behavior matrix
for (f in 1:n_focals){ #For each focal
focals[focal_id_list[f],
(focal_times[f]-focal_duration_s/2+1):(focal_times[f]+focal_duration_s/2)]=1
}
#Data observed during focals
observed_behavior_focal = behavior*focals
##############################################
#Find observed behaviors using group scans
#Assign scan times during the day
if (length(seq(scan_duration,time_in_s-scan_duration,by=scan_break_time_s))>num_scans){
#if potential scan mid-points with regular break time in sec > number of scans for the day
# Randomly set scan mid-points
scan_times = sample(seq(scan_duration,time_in_s-scan_duration,by=scan_break_time_s), num_scans)
}else{ # else, change break time to scan duration
scan_times = sample(seq(scan_duration,time_in_s-scan_duration,by=scan_duration), num_scans)}
sc=1
for (sc in 1:num_scans){ #For each scan
ids = sample(1:group_size, round(p_visibility*group_size)) #select individuals that are visible
scan_epoch = (scan_times[sc]-scan_duration/2+1):(scan_times[sc]+scan_duration/2) #scan time points
#Stagger visibility of individuals (one ID per second)
epoch = sample(1:length(scan_epoch), length(scan_epoch))
id=1
for (id in 1:length(ids)){ #for each visible id
scans[ids[id],scan_epoch[epoch[id]]]=1 #randomly scan observation to each visible ID (1 per sec)
}
}
#Data observed during scans
observed_behavior_scan = behavior*scans
n_events*behavior_duration/time_in_s
n_events/time_in_s
n_events
true_rate_behav_perID[sim,] = n_events/time_in_s
rowSums(focals!=0)
rowSums(focals!=0)/focal_duration_s
behav_timeObserved_focal_perID[sim,] = rowSums(observed_behavior_focal!=0)
rowSums(observed_behavior_focal!=0)
unique(observed_behavior_focal)
length(unique(observed_behavior_focal))
length(unique(observed_behavior_focal[1,]))
unique(observed_behavior_focal[1,])
apply(observed_behavior_focal,1,function(x) length(unique(x)))
apply(observed_behavior_focal,1,function(x) length(unique(x)-1))
apply(observed_behavior_focal,1,function(x) length(unique(x))-1)
rowSums(observed_behavior_focal!=0)/behavior_duration
focal_prop_perID[sim,] = behav_timeObserved_focal_perID[sim,]/rowSums(focals!=0)
behav_timeObserved_focal_perID[sim,]/rowSums(focals!=0)
#Load library
library(ggplot2)
################################
#Set parameters specific to the:
#1. Study population
#2. Behavior studied
#2. Observation method
n_simulations = 100 #Number of simulations
#Study population
group_size = 20 #group size
p_behavior_visibility = 0.7 # observability of behavior (common or cryptic)
p_terrain_visibility = 0.9 # visibility of individuals due to terrain (forest vs. open field)
p_visibility= p_behavior_visibility * p_terrain_visibility  # Final visibility, which is a combination of the sources of occlusions.
#Behavior studied
mean=60; sd=15
n_events = round(abs(rnorm(group_size, mean, sd))); #frequency of behavior
#number of behavioral events in the day per individual, or rarity of behavior
#Assuming each individual engages in the behavior at normally distributed frequencies)
#We could sample from another distribution (e.g. more skewed)
behavior_duration = 2 #behavior duration in sec
#Observation method
#NOTES:
# Not have a unique time per behavior? draw from a distribution around a mean?
# Visibility at individual, behavior and habitat level
#total observation time
n_hours = 7 #number of hours of observation in the day
time_in_s = n_hours*60*60 #number of seconds of observations in a day
#continuous focal
focal_duration_hrs = 1/12 #time of focal in hours (i.e. 10min)
focal_duration_s = focal_duration_hrs*3600 #focal duration in seconds
focal_break_time_min = 5 # minimum break time between focals in min
focal_break_time_s = focal_break_time_min*60 # minimum break time between focals in sec
n_focals = 20 # number of focals in a day
total_focal_h = n_focals*focal_duration_hrs #focal observation time in hours
total_focal_s = n_focals*focal_duration_s #focal observation time in seconds
#group scans
scan_obsTime_perID=1; #scan time needed per individual. Assuming 1sec
scan_duration = scan_obsTime_perID*group_size #duration of a scan observations in sec, scales with group size
scan_break_time_s = 60 # minimum break time between scans in seconds
num_scans = total_focal_s/scan_duration #equivalent # scans than the focal hours observed
#initiate outcomes of simulation
focaltime_perID = matrix(NA,n_simulations,group_size) #seconds of focal observation per ID
focalsamples_perID = matrix(NA,n_simulations,group_size)  #number of focal observations per ID
behav_timeObserved_focal_perID = matrix(NA,n_simulations,group_size)  #seconds of behavior observed per ID
behav_boutsObserved_focal_perID = matrix(NA,n_simulations,group_size)  # number of bouts observed per ID
focal_rate_perID = matrix(NA,n_simulations,group_size)  #observed rate of behavior per ID
behav_timeObserved_focal_total = matrix(NA,1,n_simulations) #seconds of behavior observed for all IDs
behav_boutsObserved_focal_total = matrix(NA,1,n_simulations) #number of bouts observed for all IDs
scansamples_perID = matrix(NA,n_simulations,group_size) # number of scan samples per ID
behav_boutsObserved_scan_perID = matrix(NA,n_simulations,group_size) # number of bouts observed per ID
scan_rate_perID = matrix(NA,n_simulations,group_size) #observed rate of behavior per ID
behav_timeObserved_scan_total = matrix(NA,1,n_simulations) #seconds of behavior observed for all IDs
behav_boutsObserved_scan_total = matrix(NA,1,n_simulations) #number of bouts observed for all IDs
true_prop_behav_perID = matrix(NA,n_simulations,group_size)
true_rate_behav_perID = matrix(NA,n_simulations,group_size)
sim=1
for (sim in 1:n_simulations){ #for all simulation simations
#Initialize matrices
# size: [number IDs X Time in sec]
behavior = matrix(0, group_size, time_in_s) #Real behaviors
focals = matrix(0, group_size, time_in_s) #Focal observation time points
scans = matrix(0, group_size, time_in_s) #Group scans time points
#######################
#Create behavior matrix
#randomly assign mid-point of behavior during the day for each individual
id=1; e=1; event_id=1
for (id in 1:group_size){ #For each individual
event_times = sample(seq(behavior_duration, time_in_s-behavior_duration,
by = behavior_duration), n_events[id] )#sample behavioral events times (mid-point of behavior)
#Sample behavioral event times during the day with a minimum
#time lapse between behavioral events ('by' time).
#Currently min time lapse = length of the behavior
#Fill in the 'real' behavior matrix
for (e in 1:length(event_times)){ #for all behavior events
behavior[id,(event_times[e]-behavior_duration/2+1):(event_times[e]+behavior_duration/2)]=event_id
#Set each behavior bout in the day with a unique identifier event_id
event_id=event_id+1
}
}
########################################################
#Find observed behaviors using continuous focal sampling
#Assign focal times during the day
#Set focal list for the day
if (group_size<n_focals){ #if there are less individuals than #focals in a day
focal_id_list=sample(1:group_size, n_focals, replace = T)
}else{ #If there are more or equal #individuals in a day
focal_id_list=sample(1:group_size, n_focals)}
#Set focal mid-points
focal_times = sample(seq(focal_duration_s,time_in_s-focal_duration_s,
by=focal_break_time_s), n_focals)
#Sample focal mid time points during the day with a minimum
#time lapse between behavioral events ('by' time).
#Currently time lapse = focal_break_time
#Fill in the 'focal' behavior matrix
for (f in 1:n_focals){ #For each focal
focals[focal_id_list[f],
(focal_times[f]-focal_duration_s/2+1):(focal_times[f]+focal_duration_s/2)]=1
}
#Data observed during focals
observed_behavior_focal = behavior*focals
##############################################
#Find observed behaviors using group scans
#Assign scan times during the day
if (length(seq(scan_duration,time_in_s-scan_duration,by=scan_break_time_s))>num_scans){
#if potential scan mid-points with regular break time in sec > number of scans for the day
# Randomly set scan mid-points
scan_times = sample(seq(scan_duration,time_in_s-scan_duration,by=scan_break_time_s), num_scans)
}else{ # else, change break time to scan duration
scan_times = sample(seq(scan_duration,time_in_s-scan_duration,by=scan_duration), num_scans)}
sc=1
for (sc in 1:num_scans){ #For each scan
ids = sample(1:group_size, round(p_visibility*group_size)) #select individuals that are visible
scan_epoch = (scan_times[sc]-scan_duration/2+1):(scan_times[sc]+scan_duration/2) #scan time points
#Stagger visibility of individuals (one ID per second)
epoch = sample(1:length(scan_epoch), length(scan_epoch))
id=1
for (id in 1:length(ids)){ #for each visible id
scans[ids[id],scan_epoch[epoch[id]]]=1 #randomly scan observation to each visible ID (1 per sec)
}
}
#Data observed during scans
observed_behavior_scan = behavior*scans
##############################################
#Evaluate scan vs. continuous sampling -based behavior observed
#True rates/proportion
true_prop_behav_perID[sim,] = n_events*behavior_duration/time_in_s #true proportion of time engaged in behavior X per ID
true_rate_behav_perID[sim,] = n_events/time_in_s #true rate of behavior X per ID
#Continuous-sampling-based estimates
focaltime_perID[sim,] = rowSums(focals!=0) #seconds of continuous observation per ID
focalsamples_perID[sim,] = rowSums(focals!=0)/focal_duration_s #number of focal observations per ID
behav_timeObserved_focal_perID[sim,] = rowSums(observed_behavior_focal!=0) #seconds of behavior observed per ID
behav_boutsObserved_focal_perID[sim,] = apply(observed_behavior_focal,1,function(x) length(unique(x))-1) # number of bouts observed per ID
focal_prop_perID[sim,] = behav_timeObserved_focal_perID[sim,]/rowSums(focals!=0) #observed proportion of time of behavior per ID
focal_rate_perID[sim,] = behav_boutsObserved_focal_perID[sim,]/rowSums(focals!=0) #observed rate of behavior per ID
# behav_timeObserved_focal_total[sim] = length(which(observed_behavior_focal!=0)) #seconds of behavior observed for all IDs
# behav_boutsObserved_focal_total[sim] = length(unique(observed_behavior_focal[which(observed_behavior_focal!=0)])) #number of bouts observed for all IDs
#Scan-sampling-based estimates
scansamples_perID[sim,] = rowSums(scans!=0) # number of scan samples per ID
behav_boutsObserved_scan_perID[sim,] = rowSums(observed_behavior_scan!=0) # number of bouts observed per ID
scan_rate_perID[sim,] = rowSums(observed_behavior_scan!=0)/rowSums(scans!=0) #observed probability of occurrence of behavior per ID
# behav_timeObserved_scan_total[sim] = length(which(observed_behavior_scan!=0))#seconds of behavior observed for all IDs
# behav_boutsObserved_scan_total[sim] = length(unique(observed_behavior_scan[which(observed_behavior_scan!=0)])) #number of bouts observed for all IDs
print(sim)
}
#Remove NAs
if (any(is.nan(focal_prop_perID))){ focal_prop_perID[is.nan(focal_prop_perID)]=0 }
if (any(is.nan(focal_rate_perID))){ focal_rate_perID[is.nan(focal_rate_perID)]=0 }
if (any(is.nan(scanl_rate_perID))){ scan_rate_perID[is.nan(scan_rate_perID)]=0 }
#initiate outcomes of simulation
focaltime_perID = matrix(NA,n_simulations,group_size) #seconds of focal observation per ID
focalsamples_perID = matrix(NA,n_simulations,group_size)  #number of focal observations per ID
behav_timeObserved_focal_perID = matrix(NA,n_simulations,group_size)  #seconds of behavior observed per ID
behav_boutsObserved_focal_perID = matrix(NA,n_simulations,group_size)  # number of bouts observed per ID
focal_prop_perID = matrix(NA,n_simulations,group_size)  #obsevred proportion of time engaged in behavior X per ID
focal_rate_perID = matrix(NA,n_simulations,group_size)  #observed rate of behavior per ID
# behav_timeObserved_focal_total = matrix(NA,1,n_simulations) #seconds of behavior observed for all IDs
# behav_boutsObserved_focal_total = matrix(NA,1,n_simulations) #number of bouts observed for all IDs
scansamples_perID = matrix(NA,n_simulations,group_size) # number of scan samples per ID
behav_boutsObserved_scan_perID = matrix(NA,n_simulations,group_size) # number of bouts observed per ID
scan_rate_perID = matrix(NA,n_simulations,group_size) #observed rate of behavior per ID
# behav_timeObserved_scan_total = matrix(NA,1,n_simulations) #seconds of behavior observed for all IDs
# behav_boutsObserved_scan_total = matrix(NA,1,n_simulations) #number of bouts observed for all IDs
true_prop_behav_perID = matrix(NA,n_simulations,group_size)
true_rate_behav_perID = matrix(NA,n_simulations,group_size)
sim=1
for (sim in 1:n_simulations){ #for all simulation simations
#Initialize matrices
# size: [number IDs X Time in sec]
behavior = matrix(0, group_size, time_in_s) #Real behaviors
focals = matrix(0, group_size, time_in_s) #Focal observation time points
scans = matrix(0, group_size, time_in_s) #Group scans time points
#######################
#Create behavior matrix
#randomly assign mid-point of behavior during the day for each individual
id=1; e=1; event_id=1
for (id in 1:group_size){ #For each individual
event_times = sample(seq(behavior_duration, time_in_s-behavior_duration,
by = behavior_duration), n_events[id] )#sample behavioral events times (mid-point of behavior)
#Sample behavioral event times during the day with a minimum
#time lapse between behavioral events ('by' time).
#Currently min time lapse = length of the behavior
#Fill in the 'real' behavior matrix
for (e in 1:length(event_times)){ #for all behavior events
behavior[id,(event_times[e]-behavior_duration/2+1):(event_times[e]+behavior_duration/2)]=event_id
#Set each behavior bout in the day with a unique identifier event_id
event_id=event_id+1
}
}
########################################################
#Find observed behaviors using continuous focal sampling
#Assign focal times during the day
#Set focal list for the day
if (group_size<n_focals){ #if there are less individuals than #focals in a day
focal_id_list=sample(1:group_size, n_focals, replace = T)
}else{ #If there are more or equal #individuals in a day
focal_id_list=sample(1:group_size, n_focals)}
#Set focal mid-points
focal_times = sample(seq(focal_duration_s,time_in_s-focal_duration_s,
by=focal_break_time_s), n_focals)
#Sample focal mid time points during the day with a minimum
#time lapse between behavioral events ('by' time).
#Currently time lapse = focal_break_time
#Fill in the 'focal' behavior matrix
for (f in 1:n_focals){ #For each focal
focals[focal_id_list[f],
(focal_times[f]-focal_duration_s/2+1):(focal_times[f]+focal_duration_s/2)]=1
}
#Data observed during focals
observed_behavior_focal = behavior*focals
##############################################
#Find observed behaviors using group scans
#Assign scan times during the day
if (length(seq(scan_duration,time_in_s-scan_duration,by=scan_break_time_s))>num_scans){
#if potential scan mid-points with regular break time in sec > number of scans for the day
# Randomly set scan mid-points
scan_times = sample(seq(scan_duration,time_in_s-scan_duration,by=scan_break_time_s), num_scans)
}else{ # else, change break time to scan duration
scan_times = sample(seq(scan_duration,time_in_s-scan_duration,by=scan_duration), num_scans)}
sc=1
for (sc in 1:num_scans){ #For each scan
ids = sample(1:group_size, round(p_visibility*group_size)) #select individuals that are visible
scan_epoch = (scan_times[sc]-scan_duration/2+1):(scan_times[sc]+scan_duration/2) #scan time points
#Stagger visibility of individuals (one ID per second)
epoch = sample(1:length(scan_epoch), length(scan_epoch))
id=1
for (id in 1:length(ids)){ #for each visible id
scans[ids[id],scan_epoch[epoch[id]]]=1 #randomly scan observation to each visible ID (1 per sec)
}
}
#Data observed during scans
observed_behavior_scan = behavior*scans
##############################################
#Evaluate scan vs. continuous sampling -based behavior observed
#True rates/proportion
true_prop_behav_perID[sim,] = n_events*behavior_duration/time_in_s #true proportion of time engaged in behavior X per ID
true_rate_behav_perID[sim,] = n_events/time_in_s #true rate of behavior X per ID
#Continuous-sampling-based estimates
focaltime_perID[sim,] = rowSums(focals!=0) #seconds of continuous observation per ID
focalsamples_perID[sim,] = rowSums(focals!=0)/focal_duration_s #number of focal observations per ID
behav_timeObserved_focal_perID[sim,] = rowSums(observed_behavior_focal!=0) #seconds of behavior observed per ID
behav_boutsObserved_focal_perID[sim,] = apply(observed_behavior_focal,1,function(x) length(unique(x))-1) # number of bouts observed per ID
focal_prop_perID[sim,] = behav_timeObserved_focal_perID[sim,]/rowSums(focals!=0) #observed proportion of time of behavior per ID
focal_rate_perID[sim,] = behav_boutsObserved_focal_perID[sim,]/rowSums(focals!=0) #observed rate of behavior per ID
# behav_timeObserved_focal_total[sim] = length(which(observed_behavior_focal!=0)) #seconds of behavior observed for all IDs
# behav_boutsObserved_focal_total[sim] = length(unique(observed_behavior_focal[which(observed_behavior_focal!=0)])) #number of bouts observed for all IDs
#Scan-sampling-based estimates
scansamples_perID[sim,] = rowSums(scans!=0) # number of scan samples per ID
behav_boutsObserved_scan_perID[sim,] = rowSums(observed_behavior_scan!=0) # number of bouts observed per ID
scan_rate_perID[sim,] = rowSums(observed_behavior_scan!=0)/rowSums(scans!=0) #observed probability of occurrence of behavior per ID
# behav_timeObserved_scan_total[sim] = length(which(observed_behavior_scan!=0))#seconds of behavior observed for all IDs
# behav_boutsObserved_scan_total[sim] = length(unique(observed_behavior_scan[which(observed_behavior_scan!=0)])) #number of bouts observed for all IDs
print(sim)
}
#Remove NAs
if (any(is.nan(focal_prop_perID))){ focal_prop_perID[is.nan(focal_prop_perID)]=0 }
if (any(is.nan(focal_rate_perID))){ focal_rate_perID[is.nan(focal_rate_perID)]=0 }
if (any(is.nan(scanl_rate_perID))){ scan_rate_perID[is.nan(scan_rate_perID)]=0 }
if (any(is.nan(scan_rate_perID))){ scan_rate_perID[is.nan(scan_rate_perID)]=0 }
df$diff_scan = abs(true_rate_results - scan_rate_results)
df$diff_focal = abs(true_rate_results - focal_rate_results)
sum(df$diff_scan); mean(df$diff_scan)
sum(df$diff_focal); mean(df$diff_focal)
#Pool results for later plotting
true_prop_results = c(true_prop_behav_perID)
true_rate_results = c(true_rate_behav_perID)
scan_rate_results = c(scan_rate_perID)
focal_rate_results = c(focal_rate_perID)
focal_prop_results = c(focal_rate_perID)
df<-data.frame(scan_rate_results, focal_rate_results,true_rate_results)
#Compute difference of rates per ID
df$diff_scan = abs(true_rate_results - scan_rate_results)
df$diff_focal = abs(true_rate_results - focal_rate_results)
sum(df$diff_scan); mean(df$diff_scan)
sum(df$diff_focal); mean(df$diff_focal)
plot_scan = density(scan_rate_results)
plot_focal = density(focal_rate_results)
plot_true = density(true_rate_results)
mean_true_rate = mean(true_rate_results)
#Pool results for later plotting
true_prop_results = c(true_prop_behav_perID)
true_rate_results = c(true_rate_behav_perID)
scan_rate_results = c(scan_rate_perID)
focal_rate_results = c(focal_rate_perID)
focal_prop_results = c(focal_prop_perID)
df<-data.frame(scan_rate_results, focal_rate_results,true_rate_results)
#Compute difference of rates per ID
df$diff_scan = abs(true_rate_results - scan_rate_results)
df$diff_focal = abs(true_rate_results - focal_rate_results)
sum(df$diff_scan); mean(df$diff_scan)
sum(df$diff_focal); mean(df$diff_focal)
plot_scan = density(scan_rate_results)
plot_focal = density(focal_rate_results)
plot_true = density(true_rate_results)
mean_true_rate = mean(true_rate_results)
y_max = max(c(max(plot_scan$y), max(plot_focal$y), max(plot_true$y)))
#Plot results
colors <- c("Scan" = "blue", "Focal" = "orange", "True"="red")
ggplot(df, aes(scan_rate_results))+
geom_vline(xintercept=mean(true_prop_behav_perID), size = 1, color="red")+ #true rate per individual
geom_density(aes(true_rate_results, color = "True"), size = 1.5)+
#annotate("text", x=mean(true_prop_behav_perID)+0.002, y=y_max+10, label="true proportion", angle=90, color='red')+
geom_density(aes(color = "Scan"), size = 1.5)+ #distribution of rate per ID from group scans
geom_vline(xintercept=median(scan_rate_results), color='blue', size = 1, linetype = 3)+ #median rate from group scans
geom_vline(xintercept=mean(scan_rate_results), color='blue', size = 1, linetype = 2)+ #mean rate from group scans
geom_density(aes(focal_rate_results, color = "Focal"), size = 1.5)+ #distribution of rate per ID from continuous focal sampling
geom_vline(xintercept=median(focal_rate_results), color='orange', size = 1, linetype = 3)+ #median rate from focal sampling
geom_vline(xintercept=mean(focal_rate_results), color='orange', size = 1, linetype = 2)+ #mean rate from focal sampling
labs(x='Proportion per ID',y='density', color="Legend")+scale_color_manual(values=colors)+ylim(c(0,y_max+40))+
theme_classic(base_size = 15)
colors <- c("Scan" = "blue", "Focal" = "orange", "True"="red")
ggplot(df, aes(scan_rate_results))+
geom_vline(xintercept=mean(true_rate_behav_perID), size = 1, color="red")+ #true rate per individual
geom_density(aes(true_rate_results, color = "True"), size = 1.5)+
#annotate("text", x=mean(true_prop_behav_perID)+0.002, y=y_max+10, label="true proportion", angle=90, color='red')+
geom_density(aes(color = "Scan"), size = 1.5)+ #distribution of rate per ID from group scans
geom_vline(xintercept=median(scan_rate_results), color='blue', size = 1, linetype = 3)+ #median rate from group scans
geom_vline(xintercept=mean(scan_rate_results), color='blue', size = 1, linetype = 2)+ #mean rate from group scans
geom_density(aes(focal_rate_results, color = "Focal"), size = 1.5)+ #distribution of rate per ID from continuous focal sampling
geom_vline(xintercept=median(focal_rate_results), color='orange', size = 1, linetype = 3)+ #median rate from focal sampling
geom_vline(xintercept=mean(focal_rate_results), color='orange', size = 1, linetype = 2)+ #mean rate from focal sampling
labs(x='Rate per ID',y='density', color="Legend")+scale_color_manual(values=colors)+ylim(c(0,y_max+40))+
theme_classic(base_size = 15)
colors <- c("Scan" = "blue", "Focal" = "orange", "True"="red")
ggplot(df, aes(scan_rate_results))+
geom_vline(xintercept=mean(true_prop_behav_perID), size = 1, color="red")+ #true proportion per individual
geom_density(aes(true_prop_results, color = "True"), size = 1.5)+
#annotate("text", x=mean(true_prop_behav_perID)+0.002, y=y_max+10, label="true proportion", angle=90, color='red')+
geom_density(aes(color = "Scan"), size = 1.5)+ #distribution of rate per ID from group scans
geom_vline(xintercept=median(scan_rate_results), color='blue', size = 1, linetype = 3)+ #median rate from group scans
geom_vline(xintercept=mean(scan_rate_results), color='blue', size = 1, linetype = 2)+ #mean rate from group scans
geom_density(aes(focal_prop_results, color = "Focal"), size = 1.5)+ #distribution of rate per ID from continuous focal sampling
geom_vline(xintercept=median(focal_prop_results), color='orange', size = 1, linetype = 3)+ #median rate from focal sampling
geom_vline(xintercept=mean(focal_prop_results), color='orange', size = 1, linetype = 2)+ #mean rate from focal sampling
labs(x='Proportion per ID',y='density', color="Legend")+scale_color_manual(values=colors)+ylim(c(0,y_max+40))+
theme_classic(base_size = 15)
y_max
##################################################################333
library(mitml)
library(lme4)
data(studentratings)
##################################################################333
library(mitml)
library(lme4)
data(studentratings)
summary(studentratings)
library(readr)
library(ggplot2)
setwd('~/Documents/GitHub/Cayo-Maria-Survival/Data/GreeneryIndex/')
#Load data for big Cayo
greenery =read.csv('Sentinel-2_NDVI-2015-03-13_TO_2023-03-13.csv')
View(greenery)
greenery =read.csv('Sentinel-2_NDVI-2015-03-13_TO_2023-03-13.csv')
greenery$C0.date = as.Date(parse_datetime(greenery$C0.date))
postHurrGreenery = greenery[which(greenery$C0.date>"2017-09-17"),]
ggplot(postHurrGreenery, aes(x=C0.date, y=C0.mean)) +
geom_point() +
geom_smooth(method=lm, se=T)
p_bigC<-ggplot(greenery, aes(x=C0.date, y=C0.mean))+
geom_point()+
geom_line()+
#geom_smooth()+
geom_vline(xintercept = as.numeric(as.Date("2017-09-17")))+
ylim(0, 0.55)+
scale_x_date(date_breaks = "1 year")+
theme_classic(base_size=15)
p_bigC
ggplot(greenery, aes(x=C0.date, y=C0.mean))+
geom_point()+
geom_line()+
#geom_smooth()+
geom_vline(xintercept = as.numeric(as.Date("2017-09-17")))+
#ylim(0, 0.55)+
scale_x_date(date_breaks = "1 year")+
theme_classic(base_size=15)
