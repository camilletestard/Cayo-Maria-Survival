if(!purrr::is_empty(idx)){
census[idx,c("DOD","Status")]=death_update2022[id, c("DOD","Status")]
}
}
#pedigree = read.csv("/PEDIGREE_2021.txt", sep = '\t')
rm(list = setdiff(ls(), "census"))
#Extract id list
group = c("F","V","KK","V","F","F","KK","V","V","KK","S","V","F","V")
years = c(2015,2015,2015,
2016,2016,2017,2017,2017,
2018, 2018,2019, 2019,2021,2021)
groupyears = c("F2015","V2015","KK2015",
"V2016","F2016","F2017",
"KK2017","V2017","V2018","KK2018",
"S2019","V2019","F2021","V2021")
meta_data.all = data.frame()
for (gy in 1:length(groupyears)){ #for all group & years
print(paste("%%%%%%%%%%%%%%%%%% ",groupyears[gy], "%%%%%%%%%%%%%%%%%%"))
#Load data
setwd('~/Documents/GitHub/Cayo-Maria-Survival/Data/Data All Cleaned/BehavioralDataFiles')
meta_data = read.csv(paste("Group",groupyears[gy],"_GroupByYear.txt", sep = "")) #load meta data
meta_data$group=group[gy]
meta_data$year.behavior = years[gy]
meta_data$id.year.behav = paste0(meta_data$id, meta_data$year.behavior)
meta_data.all = rbind(meta_data.all, meta_data[,c("id","sex","group","year.behavior","id.year.behav","ordinal.rank","percofsex.dominanted","hrs.focalfollowed","focalcutoff_met")])
}
SurvivalData = meta_data.all
#Set study period dates (consider each year separately)
start.dates = c("2017-09-17","2018-09-17","2019-09-17","2020-09-17","2021-09-17")
end.dates = c("2018-09-17","2019-09-17","2020-09-17","2021-09-17","2022-09-17")
yr=1; SurvivalData.ALL=data.frame()
for (yr in 1:length(start.dates)){
SurvivalData$study.start.date = as.Date(start.dates[yr])
SurvivalData$study.end.date = as.Date(end.dates[yr])
SurvivalData$study.period.days = SurvivalData$study.end.date - SurvivalData$study.start.date
study.period=SurvivalData$study.period.days[1]
SurvivalData$year.survival = yr
# if (group[gy] =="KK"){SurvivalData$study.end.date = study.end.date.KK}else{SurvivalData$study.end.date = study.end.date}
# if (group[gy] =="KK"){study.perod = study.perod.days.KK}else{study.perod = study.perod.days}
### Get demographic data ###
ID.idx = match(SurvivalData$id, census$AnimalID) #get the idx for the appropriate individuals
SurvivalData$Status = census$Status[ID.idx] #get status (dead, removed or alive)
SurvivalData$DOB = census$DOB[ID.idx] #get DOB
SurvivalData$age = as.numeric(SurvivalData$study.start.date -SurvivalData$DOB)/365.25
SurvivalData$DOD = census$DOD[ID.idx] #get DOD
SurvivalData$DOT = census$DateTransfer[ID.idx]#get DOT
SurvivalData$Age_entry.days = SurvivalData$study.start.date - SurvivalData$DOB #age in days at the start of the study
#Get age in days at the end of the study (until event: death, removal or end of study)
SurvivalData$Age_event.days = SurvivalData$DOD- SurvivalData$DOB #event = death
SurvivalData$Age_event.days[!is.na(SurvivalData$DOT)] = #event = removal
SurvivalData$DOT[!is.na(SurvivalData$DOT)]- SurvivalData$DOB[!is.na(SurvivalData$DOT)]
SurvivalData$Age_event.days[is.na(SurvivalData$Age_event.days)] = #event = end of study
SurvivalData$Age_entry.days[is.na(SurvivalData$Age_event.days)] + study.period
#If individual died after the study period, consider it alive
SurvivalData$Status[which(SurvivalData$DOT>SurvivalData$study.end.date[1])] = "IN CS"
SurvivalData$Status[which(SurvivalData$DOD>SurvivalData$study.end.date[1])] = "IN CS"
#Also set event days to end of study rather than DOD or DOT.
SurvivalData$Age_event.days[which(SurvivalData$DOD>SurvivalData$study.end.date[1])] = SurvivalData$Age_entry.days[which(SurvivalData$DOD>SurvivalData$study.end.date[1])] + study.period
SurvivalData$Age_event.days[which(SurvivalData$DOT>SurvivalData$study.end.date[1])] = SurvivalData$Age_entry.days[which(SurvivalData$DOT>SurvivalData$study.end.date[1])] + study.period
#Number of days in study. Total study period or until death/cull
SurvivalData$days.in.study = SurvivalData$Age_event.days-SurvivalData$Age_entry.days
#Create survival column which will be used in all models
SurvivalData$Survival = 0
SurvivalData$Survival[SurvivalData$Status=="DEAD"] = 1
#Remove individuals that were dead or transferred before the start of the study
SurvivalData= SurvivalData[SurvivalData$days.in.study>0,]
# Merge and save data
SurvivalData.ALL = rbind(SurvivalData.ALL, SurvivalData)
}
#Get year of event (or end of study)
SurvivalData.ALL$YearOfEvent = NA
SurvivalData.ALL$YearOfEvent[!is.na(SurvivalData.ALL$DOD)] = as.numeric(format(as.Date(SurvivalData.ALL$DOD[!is.na(SurvivalData.ALL$DOD)], format="%d/%m/%Y"),"%Y"))
SurvivalData.ALL$YearOfEvent[!is.na(SurvivalData.ALL$DOT)] = as.numeric(format(as.Date(SurvivalData.ALL$DOT[!is.na(SurvivalData.ALL$DOT)], format="%d/%m/%Y"),"%Y"))
SurvivalData.ALL$YearOfEvent[is.na(SurvivalData.ALL$YearOfEvent)] = 2022
#Get year of death
SurvivalData.ALL$YearOfDeath = year(SurvivalData.ALL$DOD)
#Get number of unique IDs included
allids = unique(SurvivalData.ALL$id);
unique_Survival = SurvivalData.ALL[match(allids, SurvivalData.ALL$id),]
table(unique_Survival$group); table(unique_Survival$Survival)
table(unique_Survival$group, unique_Survival$Survival)
table(unique_Survival$group,unique_Survival$YearOfDeath)
table(unique_Survival$YearOfDeath)
table(round(unique_Survival$age),unique_Survival$YearOfDeath)
#Save file for pre-hurricane sociality
save(SurvivalData.ALL,file ="~/Documents/GitHub/Cayo-Maria-Survival/Data/R.Data/Survival_Adults_TimeVarying.RData")
library(stringr)
library(igraph)
library(lubridate)
library(hms)
library(data.table)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(bisonR)
#Load functions
setwd("~/Documents/GitHub/Cayo-Maria-Survival/")
source("Code/Functions/functions_GlobalNetworkMetrics.R")
group = c("F","V","KK","V","F","F","KK","V","V","KK","S","V","F","V")
years = c(2015,2015,2015,
2016,2016,2017,2017,2017,
2018, 2018,2019, 2019,2021,2021)
groupyears = c("F2015","V2015","KK2015",
"V2016","F2016","F2017",
"KK2017","V2017","V2018","KK2018",
"S2019","V2019","F2021","V2021")
gy=1#16
edgelist.all = data.frame()
savePath = '~/Documents/GitHub/Cayo-Maria-Survival/Data/R.Data/'
print(paste("%%%%%%%%%%%%%%%%%% ",groupyears[gy], "%%%%%%%%%%%%%%%%%%"))
#Load data
setwd('~/Documents/GitHub/Cayo-Maria-Survival/Data/Data All Cleaned/BehavioralDataFiles')
groom_data = read.csv(paste("Group",groupyears[gy],"_GroomingEvents.txt", sep = ""))
meta_data = read.csv(paste("Group",groupyears[gy],"_GroupByYear.txt", sep = "")) #load meta data
groom_data$conc = paste(groom_data$groom_giver, groom_data$groom_reciever, sep=".")
if (groupyears[gy]=="HH2016"){
#Add HH dominance for subadults.
hh.dominance <- read.csv("HH_Dominance.csv");names(hh.dominance)[1]="id"
hh.dominance$id = as.character(hh.dominance$id)
hh.dominance$id[hh.dominance$id=="2.00E+09"]="2E9"
hh.dominance$id[hh.dominance$id=="2.00E+08"]="2E8"
hh.dominance$id[hh.dominance$id=="7.00E+00"]="7E0"
hh.dominance$id[hh.dominance$id=="7.00E+03"]="7E3"
hh.dominance$id[hh.dominance$id=="8.00E+02"]="8E2"
meta_data[,c("ordinal.rank","percofsex.dominanted")]=hh.dominance[match(meta_data$id, hh.dominance$id),c("ordinal.rank","percofsex.domianted")]
}
if (groupyears[gy]=="KK2017"){
#Add HH dominance for juveniles.
kk.dominance <- read.csv("KK_dominance_withSubadults.csv");names(kk.dominance)[1]="id"
meta_data[,c("ordinal.rank","percofsex.dominanted")]=kk.dominance[match(meta_data$id, kk.dominance$id),c("ordinal.rank","percofsex.domianted")]
}
#Format data with aggregate format
# Output the Master Edgelist of all possible pairs given the unique IDs.
unqIDs = meta_data$id#[meta_data$focalcutoff_met=="Y"]
edgelist = calcMasterEL_groom(unqIDs);
x<-as.data.frame(table(groom_data$conc))
edgelist$count = x$Freq[match(edgelist$conc, x$Var1)]
df_obs_agg = edgelist
df_obs_agg$count=ifelse(is.na(edgelist$count),0,edgelist$count)
names(df_obs_agg)=c("ID1", "ID2", "dyad_id","count")
df_obs_agg$duration=0
for (r in 1:nrow(df_obs_agg)){
df_obs_agg$duration[r] = sum(groom_data$constrained_duration[which(groom_data$conc==df_obs_agg$dyad_id[r])])
}
#Get observation effort for each dyad
df_obs_agg$ID1_obseff = meta_data$hrs.focalfollowed[match(df_obs_agg$ID1, meta_data$id)]
df_obs_agg$ID2_obseff = meta_data$hrs.focalfollowed[match(df_obs_agg$ID2, meta_data$id)]
df_obs_agg$total_obs_time = (df_obs_agg$ID1_obseff + df_obs_agg$ID2_obseff)
df_obs_agg$total_obs_time_sec = (df_obs_agg$ID1_obseff + df_obs_agg$ID2_obseff)*3600
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_obs_time_sec", 600)
View(df)
View(df_obs_agg)
View(meta_data)
View(groom_data)
View(df_obs_agg)
View(df)
#Load functions
setwd("~/Documents/GitHub/Cayo-Maria-Survival/")
source("Code/Functions/functions_GlobalNetworkMetrics.R")
group = c("F","V","KK","V","F","F","KK","V","V","KK","S","V","F","V")
years = c(2015,2015,2015,
2016,2016,2017,2017,2017,
2018, 2018,2019, 2019,2021,2021)
groupyears = c("F2015","V2015","KK2015",
"V2016","F2016","F2017",
"KK2017","V2017","V2018","KK2018",
"S2019","V2019","F2021","V2021")
gy=10#16
edgelist.all = data.frame()
savePath = '~/Documents/GitHub/Cayo-Maria-Survival/Data/R.Data/'
print(paste("%%%%%%%%%%%%%%%%%% ",groupyears[gy], "%%%%%%%%%%%%%%%%%%"))
#Load data
setwd('~/Documents/GitHub/Cayo-Maria-Survival/Data/Data All Cleaned/BehavioralDataFiles')
scans2018= read.csv(paste("Group",groupyears[gy],"_scansamples_FULL_CLEANED.txt", sep = ""))
meta_data = read.csv(paste("Group",groupyears[gy],"_GroupByYear.txt", sep = "")) #load meta data
#Initialize SocialCaiptalData
SocialCapitalData= meta_data[,c("id","sex","age","ordinal.rank","percofsex.dominanted","hrs.focalfollowed","focalcutoff_met")]
SocialCapitalData$group = group[gy]
SocialCapitalData$year = years[gy]
##Format data##
scans2018$date <- lubridate::mdy(as.character(scans2018$date))
scans2018$year <- lubridate::year(scans2018$date)
scans2018$Q    <- lubridate::quarter(scans2018$date)
scans2018$date <- as.character(scans2018$date) #re-format to character after finding year and quarter
#Add unique scan identifier
scans2018$observation.name = as.factor(paste(scans2018$date, scans2018$scan.num,sep="."))
#Add hurricane info
scans2018$isPost = 1
#Format time and create timeBlock column
#IMPORTANT: MAKE SURE TIME COLUMNS ARE FORMATTED IN EXCEL IN FORMAT "13:55:00"
scans2018$start.time = as_hms(as.character(scans2018$start.time))
scans2018$stop.time = as_hms(as.character(scans2018$stop.time))
scans2018$timeBlock = NA
scans2018$timeBlock[which(scans2018$start.time <= as_hms("11:00:00"))] = "AM";
scans2018$timeBlock[which(scans2018$start.time > as_hms("11:00:00"))] = "PM";
#Format XEX names
unique(scans2018$subject.ID) #check spelling of subject id
scans2018$subject.ID=sub("'","",as.character(scans2018$subject.ID)) #Replace 'XEX byXEX names if needed
scans2018$subject.ID=str_trim(scans2018$subject.ID,side="both") #Remove blanks
unique(scans2018$prox.adult.IDs)
scans2018$prox.adult.IDs=sub("'","",as.character(scans2018$prox.adult.IDs))
#Clean up: rename and delete unused columns
scans2018[,c("stop.time","observer.initials","cayo.map.code","nearest.adult.neighbour.ID","distance.nearest.neighbour","start.time")]=NULL
names(scans2018)[3]="scan.number"; names(scans2018)[4]="focalID"; names(scans2018)[5]="focal.activity"; names(scans2018)[7]="in.proximity"
#create column with equivalent activity to pre-hurricane
scans2018[] = lapply(scans2018,str_trim)
scans2018$focal.activity.isPost = as.character(scans2018$focal.activity) #preserve post-hurricane activity code
#re-code activity to pre-hurricane for comparison
scans2018$focal.activity = as.character(scans2018$focal.activity)
scans2018$focal.activity[unique(c(which(scans2018$focal.activity=='G'),which(scans2018$focal.activity=='E'),which(scans2018$focal.activity=='E,P'),which(scans2018$focal.activity=='G,E')))]="social"
scans2018$focal.activity[unique(c(which(scans2018$focal.activity=='R'),which(scans2018$focal.activity=='P')))]="rest"
scans2018$focal.activity[unique(c(which(scans2018$focal.activity=='AG'),which(scans2018$focal.activity=='AR')))]="aggression"
scans2018$focal.activity[unique(c(which(scans2018$focal.activity=='SR'),which(scans2018$focal.activity=='SG')))]="submit"
scans2018$focal.activity[grep('T',scans2018$focal.activity)]="travel"
scans2018$focal.activity[grep('F',scans2018$focal.activity)]="feed"
scans2018$focal.activity[grep('D',scans2018$focal.activity)]="drink"
scans2018$focal.activity[grep('SD',scans2018$focal.activity)]="sdb"
scans2018$focal.activity[grep('N/A',scans2018$focal.activity)]="UNK"
#unique(scans2018$focal.activity) #Check correct activity categories
#Format in.proximity, count number of prox partners
scans2018$partner.ID = as.character(scans2018$partner.ID); scans2018$partner.ID[which(scans2018$partner.ID=="N/A")]=NA
scans2018$in.proximity = as.character(scans2018$in.proximity); scans2018$in.proximity[which(scans2018$in.proximity=="N/A")]=NA
scans2018$num.prox = str_count(as.character(scans2018$in.proximity),",")+1
scans2018$num.prox[is.na(scans2018$num.prox)]=0
#Add social information
scans2018$isSocial=0; scans2018$isSocial[which(scans2018$focal.activity=="social")]=1
scans2018$isSocialGive = 0; scans2018$isSocialGive[which(scans2018$focal.activity.isPost=="G")]=1
scans2018$isSocialGet = 0; scans2018$isSocialGet[which(scans2018$focal.activity.isPost=="E")]=1
groom_data = scans2018[scans2018$isSocial==1,c("focalID","partner.ID",'focal.activity.isPost')]
groom_data$groom_giver = ifelse( groom_data$focal.activity.isPost=="G", groom_data$focalID, groom_data$partner.ID)
groom_data$groom_reciever = ifelse( groom_data$focal.activity.isPost=="E", groom_data$focalID, groom_data$partner.ID)
groom_data$conc = paste(groom_data$groom_giver, groom_data$groom_reciever, sep=".")
#Format data with aggregate format
# Output the Master Edgelist of all possible pairs given the unique IDs.
unqIDs = meta_data$id
edgelist = calcMasterEL_groom(unqIDs);
x<-as.data.frame(table(groom_data$conc))
edgelist$count = x$Freq[match(edgelist$conc, x$Var1)]
df_obs_agg = edgelist
df_obs_agg$count=ifelse(is.na(edgelist$count),0,edgelist$count)
names(df_obs_agg)=c("ID1", "ID2", "dyad_id","count")
df_obs_agg$duration = NA
numscans = as.data.frame(table(scans2018$focalID))
df_obs_agg$ID1_obseff = numscans$Freq[match(df_obs_agg$ID1, numscans$Var1)]
df_obs_agg$ID2_obseff = numscans$Freq[match(df_obs_agg$ID2, numscans$Var1)]
df_obs_agg$total_samples = (df_obs_agg$ID1_obseff + df_obs_agg$ID2_obseff)
View(df_obs_agg)
library(stringr)
library(igraph)
library(lubridate)
library(hms)
library(data.table)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
#Load functions
setwd("~/Documents/GitHub/Cayo-Maria-Disease-Modeling/")
source("Code/Functions/functions_GlobalNetworkMetrics.R")
group = c("F","V","KK","V","F","F","KK","V","V","KK","S","V","F","V")
years = c(2015,2015,2015,
2016,2016,2017,2017,2017,
2018, 2018,2019, 2019,2021,2021)
groupyears = c("F2015","V2015","KK2015",
"V2016","F2016","F2017",
"KK2017","V2017","V2018","KK2018",
"S2019","V2019","F2021","V2021")
gy=12#16
edgelist.all = data.frame()
savePath = '~/Documents/GitHub/Cayo-Maria-Disease-Modeling/Data/R.Data/'
print(paste("%%%%%%%%%%%%%%%%%% ",groupyears[gy], "%%%%%%%%%%%%%%%%%%"))
#Load data
setwd('~/Documents/GitHub/Cayo-Maria-Disease-Modeling/Data/Data All Cleaned/BehavioralDataFiles')
prox_data = read.csv(paste("Group",groupyears[gy],"_ProximityGroups.txt", sep = ""))
meta_data = read.csv(paste("Group",groupyears[gy],"_GroupByYear.txt", sep = "")) #load meta data
#cleaned_data = read.csv(paste("Group",groupyears[gy],"_CleanedData.txt", sep = ""))
#Set NA focal activity in scans to "Rest"
prox_data$focal.activity[is.na(prox_data$focal.activity)]="rest"
if (groupyears[gy]=="HH2016"){
#Add HH dominance for subadults.
hh.dominance <- read.csv("HH_Dominance.csv");names(hh.dominance)[1]="id"
hh.dominance$id = as.character(hh.dominance$id)
hh.dominance$id[hh.dominance$id=="2.00E+09"]="2E9"
hh.dominance$id[hh.dominance$id=="2.00E+08"]="2E8"
hh.dominance$id[hh.dominance$id=="7.00E+00"]="7E0"
hh.dominance$id[hh.dominance$id=="7.00E+03"]="7E3"
hh.dominance$id[hh.dominance$id=="8.00E+02"]="8E2"
meta_data[,c("ordinal.rank","percofsex.dominanted")]=hh.dominance[match(meta_data$id, hh.dominance$id),c("ordinal.rank","percofsex.domianted")]
}
if (groupyears[gy]=="KK2017"){
#Add HH dominance for juveniles.
kk.dominance <- read.csv("KK_dominance_withSubadults.csv");names(kk.dominance)[1]="id"
meta_data[,c("ordinal.rank","percofsex.dominanted")]=kk.dominance[match(meta_data$id, kk.dominance$id),c("ordinal.rank","percofsex.domianted")]
}
if (groupyears[gy] == "V2019"){ #quick fix for now
prox_idx = !is.na(prox_data$partners.activity..sequential.) #find indices where there are individuals in proximity
#add focal monkey in proximity column
prox_data$in.proximity[prox_idx]= paste(prox_data$focal.monkey[prox_idx],
prox_data$in.proximity[prox_idx],sep=",")
}
# Output the Master Edgelist of all possible pairs given the unique IDs.
unqIDs = meta_data$id#[meta_data$focalcutoff_met=="Y"]
edgelist = calcMasterEL(unqIDs);
df_obs_agg  = calcEdgeList(prox_data, edgelist); ##IMPORTANT NOTE: the structure of the proximity data is different for
#2018 relative to other years (the focal ID is not counted in proximity for 2018 but it is for other years)
#This is not a problem because the focal ID column name is not the same so the function works properly as is.
names(df_obs_agg)=c("ID1", "ID2", "dyad_id","count")
#Get observation effort for each dyad
if (years[gy]==2018){numscans = as.data.frame(table(prox_data$focalID))}else{ numscans = as.data.frame(table(prox_data$focal.monkey))}
df_obs_agg$ID1_obseff_duration = meta_data$hrs.focalfollowed[match(df_obs_agg$ID1, meta_data$id)]
df_obs_agg$ID1_obseff_samples = numscans$Freq[match(df_obs_agg$ID1, numscans$Var1)]
df_obs_agg$ID2_obseff_duration = meta_data$hrs.focalfollowed[match(df_obs_agg$ID2, meta_data$id)]
df_obs_agg$ID2_obseff_samples = numscans$Freq[match(df_obs_agg$ID2, numscans$Var1)]
df_obs_agg$total_obs_time = df_obs_agg$ID1_obseff_duration  + df_obs_agg$ID2_obseff_duration
df_obs_agg$total_samples = df_obs_agg$ID1_obseff_samples + df_obs_agg$ID2_obseff_samples
View(df_obs_agg)
#Load functions
setwd("~/Documents/GitHub/Cayo-Maria-Survival/")
source("Code/Functions/functions_GlobalNetworkMetrics.R")
group = c("F","V","KK","V","F","F","KK","V","V","KK","S","V","F","V")
years = c(2015,2015,2015,
2016,2016,2017,2017,2017,
2018, 2018,2019, 2019,2021,2021)
groupyears = c("F2015","V2015","KK2015",
"V2016","F2016","F2017",
"KK2017","V2017","V2018","KK2018",
"S2019","V2019","F2021","V2021")
gy=1#16
edgelist.all = data.frame()
savePath = '~/Documents/GitHub/Cayo-Maria-Survival/Data/R.Data/'
#Load data
setwd('~/Documents/GitHub/Cayo-Maria-Survival/Data/Data All Cleaned/BehavioralDataFiles')
groom_data = read.csv(paste("Group",groupyears[gy],"_GroomingEvents.txt", sep = ""))
meta_data = read.csv(paste("Group",groupyears[gy],"_GroupByYear.txt", sep = "")) #load meta data
groom_data$conc = paste(groom_data$groom_giver, groom_data$groom_reciever, sep=".")
if (groupyears[gy]=="HH2016"){
#Add HH dominance for subadults.
hh.dominance <- read.csv("HH_Dominance.csv");names(hh.dominance)[1]="id"
hh.dominance$id = as.character(hh.dominance$id)
hh.dominance$id[hh.dominance$id=="2.00E+09"]="2E9"
hh.dominance$id[hh.dominance$id=="2.00E+08"]="2E8"
hh.dominance$id[hh.dominance$id=="7.00E+00"]="7E0"
hh.dominance$id[hh.dominance$id=="7.00E+03"]="7E3"
hh.dominance$id[hh.dominance$id=="8.00E+02"]="8E2"
meta_data[,c("ordinal.rank","percofsex.dominanted")]=hh.dominance[match(meta_data$id, hh.dominance$id),c("ordinal.rank","percofsex.domianted")]
}
if (groupyears[gy]=="KK2017"){
#Add HH dominance for juveniles.
kk.dominance <- read.csv("KK_dominance_withSubadults.csv");names(kk.dominance)[1]="id"
meta_data[,c("ordinal.rank","percofsex.dominanted")]=kk.dominance[match(meta_data$id, kk.dominance$id),c("ordinal.rank","percofsex.domianted")]
}
#Format data with aggregate format
# Output the Master Edgelist of all possible pairs given the unique IDs.
unqIDs = meta_data$id#[meta_data$focalcutoff_met=="Y"]
edgelist = calcMasterEL_groom(unqIDs);
x<-as.data.frame(table(groom_data$conc))
edgelist$count = x$Freq[match(edgelist$conc, x$Var1)]
df_obs_agg = edgelist
df_obs_agg$count=ifelse(is.na(edgelist$count),0,edgelist$count)
names(df_obs_agg)=c("ID1", "ID2", "dyad_id","count")
df_obs_agg$duration=0
for (r in 1:nrow(df_obs_agg)){
df_obs_agg$duration[r] = sum(groom_data$constrained_duration[which(groom_data$conc==df_obs_agg$dyad_id[r])])
}
#Get observation effort for each dyad
df_obs_agg$ID1_obseff = meta_data$hrs.focalfollowed[match(df_obs_agg$ID1, meta_data$id)]
df_obs_agg$ID2_obseff = meta_data$hrs.focalfollowed[match(df_obs_agg$ID2, meta_data$id)]
df_obs_agg$total_obseff = (df_obs_agg$ID1_obseff + df_obs_agg$ID2_obseff)
df_obs_agg$total_samples = (df_obs_agg$ID1_obseff + df_obs_agg$ID2_obseff)*3600
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_obs_time_sec", 600)
d
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_samples", 600)
View(df)
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_samples", 300)
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_samples", 200)
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_samples", 100)
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_samples", 300)
max(groom_data$constrained_duration)
mean(groom_data$constrained_duration)
df<-bisonR::convert_duration_to_binary(df_obs_agg, "duration","total_samples", round(mean(groom_data$constrained_duration)))
cor.test(df$count,df$duration)
#Load libraries
#bison package
library(bisonR)
library(dplyr)
library(brms)
#Survival analysis
library(survival)
library(survminer)
library(coxme)
#For plotting
library(ggplot2)
#Load data
data_path = "~/Documents/GitHub/Cayo-Maria-Survival/Data/R.Data/"
load(paste0(data_path,"proximity_data.RData"))
edgelist.all$groupyear = paste0(edgelist.all$group, edgelist.all$year)
#Set group year list
group = c("F","V","KK","V","F","F","KK","V","V","KK","S","V","F","V")
years = c(2015,2015,2015,
2016,2016,2017,2017,2017,
2018, 2018,2019, 2019,2021,2021)
groupyears = c("F2015","V2015","KK2015",
"V2016","F2016","F2017",
"KK2017","V2017","V2018","KK2018",
"S2019","V2019","F2021","V2021")
#groupyears = c("V2015","V2016","V2017","V2018","V2019","V2021")
#Initialize lists
gy=1; fit.el.all=list(); el.all=list(); node.list=list(); posterior.el=list()
node_strength_samples = list(); density_samples=list()
#Set parameters
num_iter = 100
for (gy in 1:length(groupyears)){
##############################################################
## STEP 1: Fit network for binary data  (i.e., proximity) ###
##############################################################
# This step fits an edge weight model using conjugate priors,
# capturing uncertainty in social network edges
priors <- get_default_priors("binary_conjugate")#define priors
priors$edge <- "beta(0.1,0.1)" # set less flat priors
#prior_check(priors, "binary_conjugate")
el = edgelist.all[edgelist.all$groupyear==groupyears[gy],]
el$year=factor(el$year)
unqids = unique(c(el$ID1, el$ID2))
#Note: unique ID1 and ID2 nodes = n=1 (because self-edge do not exist)
ID1_nodes = el[match(unqids, el$ID1),c("ID1","ID1_obseff_duration",
"ID1_obseff_samples","ID1_sex","ID1_age",
"ID1_rank","group","year","isPost","groupyear")]
ID2_nodes = el[match(unqids, el$ID2),c("ID2","ID2_obseff_duration",
"ID2_obseff_samples","ID2_sex","ID2_age",
"ID2_rank","group","year","isPost","groupyear")]
ID1_nodes[nrow(ID1_nodes),]=ID2_nodes[nrow(ID2_nodes),]
node.list[[gy]]<-ID1_nodes
#Fit network with bison
fit.el <- bison_model(
(count | total_samples) ~ dyad(ID1, ID2),
data=el,
model_type = "binary_conjugate", #Count conjugate for aggression data
priors=priors,
num_draws=500
)
#Check model fit
#plot_predictions(fit.el, num_draws=20)
#Left plot: The predictions from the model are shown in blue and the real data
#are shown in black. Ideally the blue lines should be distributed around the
#black line, indicating the real data are among the possible predictions of the model.
#Right plot: comparison of predictions against point estimates of edge weights
#We're happy with current predictions
# #Summary of edge weights and their credible intervals
# summary(fit.el)
#
# #Visualize network with uncertainty estimates
# plot_network(fit.el, lwd=5)
# #Draw n edgelists from the posterior of the network
# samples.post<-draw_edgelist_samples(fit.el, num_draws=num_iter)
# samples.post[,c(3:ncol(samples.post))]<-plogis(as.matrix(samples.post[,c(3:ncol(samples.post))])) #Convert back from log scale
# posterior.el[[groupyears[gy]]] <- samples.post #save
#Draw network metrics from posterior (global, nodal and edge_weight)
#edge_weight_samples <- extract_metric(fit.el, "edge_weight", num_draws =1)
#Irrespective of num_draws, there are 10,000samples extracted
#plot(plogis(edge_weight_samples))
node_strength_samples[[groupyears[gy]]] <- extract_metric(fit.el, "node_strength", num_draws =num_iter) #Output size: num_draws X num_nodes
density_samples[[groupyears[gy]]] <-extract_metric(fit.el, "global_density", num_draws =num_iter)
#What about other metrics like modularity? Is that easy to add?=
fit.el.all[[groupyears[gy]]] <-fit.el
el.all[[groupyears[gy]]] <-el
print(groupyears[gy])
}
#Fit network with bison
fit.el <- bison_model(
(count | total_samples) ~ dyad(ID1, ID2),
data=el,
model_type = "binary_conjugate", #Count conjugate for aggression data
priors=priors,
num_draw=500
)
fit.el <- bison_model(
(count | total_samples) ~ dyad(ID1, ID2),
data=el,
model_type = "binary_conjugate", #Count conjugate for aggression data
priors=priors,
iter_sampling=100,
iter_warmup=100,
)
plot_predictions(fit.el, num_draws=20)
fit.el <- bison_model(
(count | total_samples) ~ dyad(ID1, ID2),
data=el,
model_type = "binary_conjugate", #Count conjugate for aggression data
priors=priors,
iter_sampling=1000,
iter_warmup=1000,
)
#Fit network with bison
fit.el <- bison_model(
(count | total_samples) ~ dyad(ID1, ID2),
data=el,
model_type = "binary_conjugate", #Count conjugate for aggression data
priors=priors,
iter_sampling=100,
iter_warmup=100,
)
update.packages("bisonR")
library(bisonR)
packageVersion()
packageVersion(bisonR)
packageVersion("bisonR")
library(bisonR)
packageVersion(bisonR)
update.packages("bisonR")
packageVersion("bisonR")
remotes::install_github("JHart96/bisonR")
